卷积神经网络(Convolutional Neural Network, CNN)
    卷积神经网络也是通过一层一层的节点组织起来的。和全连接神经网络一样，卷积神经网络中的每一个节点都是一个神经元。
    卷积神经网络相邻两层之间只有部分节点相连，为了展示每一层神经元的维度，一般会将每一层卷积层的节点组织成一个三维矩阵。
    全连接神经网络参数过多，将导致计算速度减慢和过拟合问题，而卷积神经网络可以有效地减少神经网络中参数的个数。
    卷积神经网络中前几层中每一个节点只和上一层中部分的节点相连。
	
    一个卷积神经网络主要由5种结构组成：输入层、卷积层、池化层、全连接层、Softmax层。
    1.输入层。输入层是整个神经网络的输入，在处理图像的卷积神经网络中，它一般代表了一张图片的像素矩阵。卷积神经网络通过不同
的神经网络结构将上一层的三维矩阵转化为下一层的三维矩阵，直到最后的全连接层。
    2.卷积层。卷积层中每一个节点的输入只是上一层神经网络的一小块，这个小块常用的大小有3×3或者5×5。卷积层试图将神经网络中的
每一小块进行更加深入地分析从而得到抽象程度更高的特征。一般来说，通过卷积层处理过的节点矩阵会变得更深。
    3.池化层。池化层不会改变三维矩阵的深度，但是它可以缩小矩阵的大小。使用池化层既可以加快计算速度也有防止过拟合问题的作用。
    4.全连接层。经过几轮卷积层和池化层的处理之后，可以认为图像中的信息已经被抽象成了信息含量更高的特征。我们可以将卷积层和
池化层看成自动图像特征提取的过程。
	
    过滤器可以将当前层神经网络上的一个子节点矩阵转化为下一层神经网络上的一个单位节点矩阵。单位节点矩阵指的是一个长和宽都为
1，但深度不限的节点矩阵。
    过滤器的尺寸指的是一个过滤器输入节点矩阵的大小，而深度指的是输出单位节点矩阵的深度。

    迁移学习，就是将一个问题上训练好的模型通过简单的调整，使其适用于一个新的问题。可以保留训练好的模型中所有卷积层的参数，
只是替换最后一层全连接层。在最后这一层全连接层之前的网络层称之为瓶颈层(bottleneck)。

循环神经网络(Recurrent Neural Networks, RNN)
LSTM（Long Short-Term Memory）
词向量（word embedding）
    基于神经网络的分布表示（distributed representation）一般称为词向量

Tensor就是张量，张量可以被简单地理解为多维数组（n阶张量为n维数组）。
Flow直接翻译就是“流”，它直观地表达了张量之间通过计算相互转化的过程。
TensorFlow中的每一个计算都是计算图上的一个节点，而节点之间的边描述了计算之间的依赖关系。

全连接神经网络:相邻两层之间任意两个节点之间都有连接。
前向传播(forward propagation)
反向传播(Back propagation, BP)
    BP算法(即误差反向传播算法)是在有导师指导下，适合于多层神经元网络的一种学习算法，它建立在梯度下降（gradient decent）法
的基础上。
    梯度下降算法主要用于单个参数的取值，而反向传播算法给出了一个高效的方式在所有参数上使用梯度下降算法，从而试神经网络模型
在训练数据上的损失函数尽可能小。
    反向传播算法主要由两个环节(激励传播、权重更新)反复循环迭代，直到网络的对输入的响应达到预定的目标范围为止。
    BP算法的学习过程由正向传播过程和反向传播过程组成。在正向传播过程中，输入信息通过输入层经隐含层，逐层处理并传向输出层。
如果在输出层得不到期望的输出值，则取输出与期望的误差的平方和作为目标函数，转入反向传播，逐层求出目标函数对各神经元权值的偏
导数，构成目标函数对权值向量的梯量，作为修改权值的依据，网络的学习在权值修改过程中完成。误差达到所期望值时，网络学习结束。
    
TensorFLow中三个基本概念：计算图(tf.Graph)、张量(tf.Tensor)和会话(tf.Session)
    计算图是TensorFlow的计算模型，所有的TensorFlow的程序都会通过计算图的形式表示。计算图上的每个节点都是一个运算，而计算
图上的边则表示了运算之间的数据传递关系。
    TensorFlow中所有运算的输入、输出都是张量。张量本身并不储存任何数据，它只是对运算结果的引用。
    会话是TensorFlow的运算模型，它管理了一个TensorFlow程序拥有的系统资源，所有的运算都要通过会话执行。

维基百科对深度学习的定义为“一类通过多层非线性变换对高复杂性数据建模算法的合集”。深度学习两个重要特性：多层、非线性。

激活函数实现去线性化：如果将每一个神经元（也就是神经网络中的节点）的输出通过一个非线性函数，那么整个神经网络的模型也就不再
是线性的了。这个非线性函数就是激活函数。


